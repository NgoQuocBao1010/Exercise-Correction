{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[89097]: Class CaptureDelegate is implemented in both /Users/fuixlabsdev1/Programming/PP/graduation-thesis/env/lib/python3.8/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x11597c860) and /Users/fuixlabsdev1/Programming/PP/graduation-thesis/env/lib/python3.8/site-packages/cv2/cv2.abi3.so (0x15e322480). One of the two will be used. Which one is undefined.\n",
      "objc[89097]: Class CVWindow is implemented in both /Users/fuixlabsdev1/Programming/PP/graduation-thesis/env/lib/python3.8/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x106350a68) and /Users/fuixlabsdev1/Programming/PP/graduation-thesis/env/lib/python3.8/site-packages/cv2/cv2.abi3.so (0x15e3224d0). One of the two will be used. Which one is undefined.\n",
      "objc[89097]: Class CVView is implemented in both /Users/fuixlabsdev1/Programming/PP/graduation-thesis/env/lib/python3.8/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x106350a90) and /Users/fuixlabsdev1/Programming/PP/graduation-thesis/env/lib/python3.8/site-packages/cv2/cv2.abi3.so (0x15e3224f8). One of the two will be used. Which one is undefined.\n",
      "objc[89097]: Class CVSlider is implemented in both /Users/fuixlabsdev1/Programming/PP/graduation-thesis/env/lib/python3.8/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x106350ab8) and /Users/fuixlabsdev1/Programming/PP/graduation-thesis/env/lib/python3.8/site-packages/cv2/cv2.abi3.so (0x15e322520). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Drawing helpers\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make some pose detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"../data/plank/plank_2.mov\")\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "        image = cv2.flip(image, 1)\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks and connections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, mp_drawing.DrawingSpec(color=(244, 117, 66), thickness=2, circle_radius=4), mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow(\"CV2\", image)\n",
    "\n",
    "        # Press Q to close cv2 window\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # (Optional)Fix bugs cannot close windows in MacOS (https://stackoverflow.com/questions/6116564/destroywindow-does-not-close-window-on-mac-using-python-and-opencv)\n",
    "    for i in range (1, 5):\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build dataset from collected videos and picture from Kaggle to .csv file for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Determine important keypoints and set up important functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 stages that I try to classify for Plank Exercise Correction:\n",
    "\n",
    "- Correct: \"C\"\n",
    "- Back is too low: \"L\"\n",
    "- Back is too high: \"H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine important landmarks for plank\n",
    "IMPORTANT_LMS = [\n",
    "    \"NOSE\",\n",
    "    \"LEFT_SHOULDER\",\n",
    "    \"RIGHT_SHOULDER\",\n",
    "    \"LEFT_ELBOW\",\n",
    "    \"RIGHT_ELBOW\",\n",
    "    \"LEFT_WRIST\",\n",
    "    \"RIGHT_WRIST\",\n",
    "    \"LEFT_HIP\",\n",
    "    \"RIGHT_HIP\",\n",
    "    \"LEFT_KNEE\",\n",
    "    \"RIGHT_KNEE\",\n",
    "    \"LEFT_ANKLE\",\n",
    "    \"RIGHT_ANKLE\",\n",
    "    \"LEFT_HEEL\",\n",
    "    \"RIGHT_HEEL\",\n",
    "    \"LEFT_FOOT_INDEX\",\n",
    "    \"RIGHT_FOOT_INDEX\",\n",
    "]\n",
    "\n",
    "# Generate all columns of the data frame\n",
    "\n",
    "HEADERS = [\"label\"] # Label column\n",
    "\n",
    "for lm in IMPORTANT_LMS:\n",
    "    HEADERS += [f\"{lm.lower()}_x\", f\"{lm.lower()}_y\", f\"{lm.lower()}_z\", f\"{lm.lower()}_v\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Set up important functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_frame(frame, percent=50):\n",
    "    '''\n",
    "    Rescale a frame to a certain percentage compare to its original frame\n",
    "    '''\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "def init_csv(dataset_path: str):\n",
    "    '''\n",
    "    Create a blank csv file with just columns\n",
    "    '''\n",
    "\n",
    "    # Ignore if file is already exist\n",
    "    if os.path.exists(dataset_path):\n",
    "        return\n",
    "\n",
    "    # Write all the columns to a empaty file\n",
    "    with open(dataset_path, mode=\"w\", newline=\"\") as f:\n",
    "        csv_writer = csv.writer(f, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(HEADERS)\n",
    "\n",
    "\n",
    "def export_landmark_to_csv(dataset_path: str, results, action: str) -> None:\n",
    "    '''\n",
    "    Export Labeled Data from detected landmark to csv\n",
    "    '''\n",
    "    landmarks = results.pose_landmarks.landmark\n",
    "    keypoints = []\n",
    "\n",
    "    try:\n",
    "        # Extract coordinate of important landmarks\n",
    "        for lm in IMPORTANT_LMS:\n",
    "            keypoint = landmarks[mp_pose.PoseLandmark[lm].value]\n",
    "            keypoints.append([keypoint.x, keypoint.y, keypoint.z, keypoint.visibility])\n",
    "        \n",
    "        keypoints = list(np.array(keypoints).flatten())\n",
    "\n",
    "        # Insert action as the label (first column)\n",
    "        keypoints.insert(0, action)\n",
    "\n",
    "        # Append new row to .csv file\n",
    "        with open(dataset_path, mode=\"a\", newline=\"\") as f:\n",
    "            csv_writer = csv.writer(f, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(keypoints)\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "\n",
    "def describe_dataset(dataset_path: str):\n",
    "    '''\n",
    "    Describe dataset\n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    print(f\"Headers: {list(data.columns.values)}\")\n",
    "    print(f'Number of rows: {data.shape[0]} \\nNumber of columns: {data.shape[1]}\\n')\n",
    "    print(f\"Labels: \\n{data['label'].value_counts()}\\n\")\n",
    "    print(f\"Missing values: {data.isnull().values.any()}\\n\")\n",
    "    \n",
    "    duplicate = data[data.duplicated()]\n",
    "    print(f\"Duplicate Rows : {len(duplicate.sum(axis=1))}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_duplicate_rows(dataset_path: str):\n",
    "    '''\n",
    "    Remove duplicated data from the dataset then save it to another files\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "    df.to_csv(f\"cleaned_dataset.csv\", sep=',', encoding='utf-8', index=False)\n",
    "    \n",
    "\n",
    "def concat_csv_files_with_same_headers(file_paths: list, saved_path: str):\n",
    "    '''\n",
    "    Concat different csv files\n",
    "    '''\n",
    "    all_df = []\n",
    "    for path in file_paths:\n",
    "        df = pd.read_csv(path, index_col=None, header=0)\n",
    "        all_df.append(df)\n",
    "    \n",
    "    results = pd.concat(all_df, axis=0, ignore_index=True)\n",
    "    results.to_csv(saved_path, sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Extract from video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"bad_data_high_hip.csv\"\n",
    "\n",
    "cap = cv2.VideoCapture(\"../data/plank/bad/plank_bad_high_4.mp4\")\n",
    "save_counts = 0\n",
    "\n",
    "# init_csv(DATASET_PATH)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.8, min_tracking_confidence=0.9) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Reduce size of a frame\n",
    "        image = rescale_frame(image, 60)\n",
    "        image = cv2.flip(image, 1)\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks and connections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, mp_drawing.DrawingSpec(color=(244, 117, 66), thickness=2, circle_radius=4), mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        # Display the saved count\n",
    "        cv2.putText(image, f\"Saved: {save_counts}\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"CV2\", image)\n",
    "\n",
    "        # Pressed key for action\n",
    "        k = cv2.waitKey(30) & 0xFF\n",
    "\n",
    "        # Press C to save as correct form\n",
    "        if k == ord('c'): \n",
    "            export_landmark_to_csv(DATASET_PATH, results, \"C\")\n",
    "            save_counts += 1\n",
    "        # Press L to save as low back\n",
    "        elif k == ord(\"l\"):\n",
    "            export_landmark_to_csv(DATASET_PATH, results, \"L\")\n",
    "            save_counts += 1\n",
    "        # Press L to save as high back\n",
    "        elif k == ord(\"h\"):\n",
    "            export_landmark_to_csv(DATASET_PATH, results, \"H\")\n",
    "            save_counts += 1\n",
    "\n",
    "        # Press q to stop\n",
    "        elif k == ord(\"q\"):\n",
    "            break\n",
    "        else: continue\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # (Optional)Fix bugs cannot close windows in MacOS (https://stackoverflow.com/questions/6116564/destroywindow-does-not-close-window-on-mac-using-python-and-opencv)\n",
    "    for i in range (1, 5):\n",
    "        cv2.waitKey(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['label', 'nose_x', 'nose_y', 'nose_z', 'nose_v', 'left_shoulder_x', 'left_shoulder_y', 'left_shoulder_z', 'left_shoulder_v', 'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_z', 'right_shoulder_v', 'left_elbow_x', 'left_elbow_y', 'left_elbow_z', 'left_elbow_v', 'right_elbow_x', 'right_elbow_y', 'right_elbow_z', 'right_elbow_v', 'left_wrist_x', 'left_wrist_y', 'left_wrist_z', 'left_wrist_v', 'right_wrist_x', 'right_wrist_y', 'right_wrist_z', 'right_wrist_v', 'left_hip_x', 'left_hip_y', 'left_hip_z', 'left_hip_v', 'right_hip_x', 'right_hip_y', 'right_hip_z', 'right_hip_v', 'left_knee_x', 'left_knee_y', 'left_knee_z', 'left_knee_v', 'right_knee_x', 'right_knee_y', 'right_knee_z', 'right_knee_v', 'left_ankle_x', 'left_ankle_y', 'left_ankle_z', 'left_ankle_v', 'right_ankle_x', 'right_ankle_y', 'right_ankle_z', 'right_ankle_v', 'left_heel_x', 'left_heel_y', 'left_heel_z', 'left_heel_v', 'right_heel_x', 'right_heel_y', 'right_heel_z', 'right_heel_v', 'left_foot_index_x', 'left_foot_index_y', 'left_foot_index_z', 'left_foot_index_v', 'right_foot_index_x', 'right_foot_index_y', 'right_foot_index_z', 'right_foot_index_v']\n",
      "Number of rows: 2556 \n",
      "Number of columns: 69\n",
      "\n",
      "Labels: \n",
      "H    2556\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Missing values: False\n",
      "\n",
      "Duplicate Rows : 0\n"
     ]
    }
   ],
   "source": [
    "df = describe_dataset(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['label', 'nose_x', 'nose_y', 'nose_z', 'nose_v', 'left_shoulder_x', 'left_shoulder_y', 'left_shoulder_z', 'left_shoulder_v', 'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_z', 'right_shoulder_v', 'left_elbow_x', 'left_elbow_y', 'left_elbow_z', 'left_elbow_v', 'right_elbow_x', 'right_elbow_y', 'right_elbow_z', 'right_elbow_v', 'left_wrist_x', 'left_wrist_y', 'left_wrist_z', 'left_wrist_v', 'right_wrist_x', 'right_wrist_y', 'right_wrist_z', 'right_wrist_v', 'left_hip_x', 'left_hip_y', 'left_hip_z', 'left_hip_v', 'right_hip_x', 'right_hip_y', 'right_hip_z', 'right_hip_v', 'left_knee_x', 'left_knee_y', 'left_knee_z', 'left_knee_v', 'right_knee_x', 'right_knee_y', 'right_knee_z', 'right_knee_v', 'left_ankle_x', 'left_ankle_y', 'left_ankle_z', 'left_ankle_v', 'right_ankle_x', 'right_ankle_y', 'right_ankle_z', 'right_ankle_v', 'left_heel_x', 'left_heel_y', 'left_heel_z', 'left_heel_v', 'right_heel_x', 'right_heel_y', 'right_heel_z', 'right_heel_v', 'left_foot_index_x', 'left_foot_index_y', 'left_foot_index_z', 'left_foot_index_v', 'right_foot_index_x', 'right_foot_index_y', 'right_foot_index_z', 'right_foot_index_v']\n",
      "Number of rows: 9751 \n",
      "Number of columns: 69\n",
      "\n",
      "Labels: \n",
      "C    3792\n",
      "L    3403\n",
      "H    2556\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Missing values: False\n",
      "\n",
      "Duplicate Rows : 0\n"
     ]
    }
   ],
   "source": [
    "# csv_files = [os.path.join(\"./\", f) for f in os.listdir(\"./\") if \"csv\" in f]\n",
    "\n",
    "# concat_csv_files_with_same_headers(csv_files, \"dataset_new.csv\")\n",
    "\n",
    "df = describe_dataset(\"./dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Extract from Kaggle dataset ([download here](https://www.kaggle.com/datasets/niharika41298/yoga-poses-dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = \"../data/kaggle/TRAIN/plank\"\n",
    "picture_files = [os.path.join(FOLDER_PATH, f) for f in os.listdir(FOLDER_PATH) if os.path.isfile(os.path.join(FOLDER_PATH, f))]\n",
    "print(f\"Total pictures: {len(picture_files)}\")\n",
    "\n",
    "DATASET_PATH = \"./data.csv\"\n",
    "saved_counts = 0\n",
    "\n",
    "# init_csv(DATASET_PATH)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.5) as pose:\n",
    "    index = 0\n",
    "    \n",
    "    while True:\n",
    "        if index == len(picture_files):\n",
    "            break\n",
    "        \n",
    "        file_path = picture_files[index]\n",
    "\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        # Flip image horizontally for more data\n",
    "        # image = cv2.flip(image, 1)\n",
    "\n",
    "        # get dimensions of image\n",
    "        dimensions = image.shape\n",
    "        \n",
    "        # height, width, number of channels in image\n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "        channels = image.shape[2]\n",
    "\n",
    "        # Reduce size of a frame\n",
    "        if width > 1000:\n",
    "            image = rescale_frame(image, 60)\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks and connections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, mp_drawing.DrawingSpec(color=(244, 117, 66), thickness=2, circle_radius=4), mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        # Display the saved count\n",
    "        cv2.putText(image, f\"Saved: {saved_counts}\", (20, 20), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow(\"CV2\", image)\n",
    "\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if k == ord('d'): \n",
    "            index += 1\n",
    "\n",
    "        elif k == ord(\"s\"):\n",
    "            export_landmark_to_csv(DATASET_PATH, results, \"C\")\n",
    "            saved_counts += 1\n",
    "\n",
    "        elif k == ord(\"f\"):\n",
    "            index += 1\n",
    "            os.remove(file_path)\n",
    "\n",
    "        elif k == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # # Press Q to close cv2 window\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('d'):\n",
    "        #     index += 1\n",
    "\n",
    "        # # Press Q to close cv2 window\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     break\n",
    "\n",
    "    # Close cv2 window\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # (Optional)Fix bugs cannot close windows in MacOS (https://stackoverflow.com/questions/6116564/destroywindow-does-not-close-window-on-mac-using-python-and-opencv)\n",
    "    for i in range (1, 5):\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = describe_dataset(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Processed Collected Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = describe_dataset(\"./dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Describe data and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['label', 'nose_x', 'nose_y', 'nose_z', 'nose_v', 'left_shoulder_x', 'left_shoulder_y', 'left_shoulder_z', 'left_shoulder_v', 'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_z', 'right_shoulder_v', 'left_elbow_x', 'left_elbow_y', 'left_elbow_z', 'left_elbow_v', 'right_elbow_x', 'right_elbow_y', 'right_elbow_z', 'right_elbow_v', 'left_wrist_x', 'left_wrist_y', 'left_wrist_z', 'left_wrist_v', 'right_wrist_x', 'right_wrist_y', 'right_wrist_z', 'right_wrist_v', 'left_hip_x', 'left_hip_y', 'left_hip_z', 'left_hip_v', 'right_hip_x', 'right_hip_y', 'right_hip_z', 'right_hip_v', 'left_knee_x', 'left_knee_y', 'left_knee_z', 'left_knee_v', 'right_knee_x', 'right_knee_y', 'right_knee_z', 'right_knee_v', 'left_ankle_x', 'left_ankle_y', 'left_ankle_z', 'left_ankle_v', 'right_ankle_x', 'right_ankle_y', 'right_ankle_z', 'right_ankle_v', 'left_heel_x', 'left_heel_y', 'left_heel_z', 'left_heel_v', 'right_heel_x', 'right_heel_y', 'right_heel_z', 'right_heel_v', 'left_foot_index_x', 'left_foot_index_y', 'left_foot_index_z', 'left_foot_index_v', 'right_foot_index_x', 'right_foot_index_y', 'right_foot_index_z', 'right_foot_index_v']\n",
      "Number of rows: 9751 \n",
      "Number of columns: 69\n",
      "\n",
      "Labels: \n",
      "C    3792\n",
      "L    3403\n",
      "H    2556\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Missing values: False\n",
      "\n",
      "Duplicate Rows : 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>nose_z</th>\n",
       "      <th>nose_v</th>\n",
       "      <th>left_shoulder_x</th>\n",
       "      <th>left_shoulder_y</th>\n",
       "      <th>left_shoulder_z</th>\n",
       "      <th>left_shoulder_v</th>\n",
       "      <th>right_shoulder_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_heel_z</th>\n",
       "      <th>right_heel_v</th>\n",
       "      <th>left_foot_index_x</th>\n",
       "      <th>left_foot_index_y</th>\n",
       "      <th>left_foot_index_z</th>\n",
       "      <th>left_foot_index_v</th>\n",
       "      <th>right_foot_index_x</th>\n",
       "      <th>right_foot_index_y</th>\n",
       "      <th>right_foot_index_z</th>\n",
       "      <th>right_foot_index_v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H</td>\n",
       "      <td>0.468005</td>\n",
       "      <td>0.560652</td>\n",
       "      <td>-0.020740</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.501118</td>\n",
       "      <td>0.497534</td>\n",
       "      <td>-0.148594</td>\n",
       "      <td>0.999583</td>\n",
       "      <td>0.512936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168519</td>\n",
       "      <td>0.497204</td>\n",
       "      <td>0.916713</td>\n",
       "      <td>0.682381</td>\n",
       "      <td>-0.064803</td>\n",
       "      <td>0.822842</td>\n",
       "      <td>0.904292</td>\n",
       "      <td>0.667422</td>\n",
       "      <td>0.114563</td>\n",
       "      <td>0.406391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H</td>\n",
       "      <td>0.470203</td>\n",
       "      <td>0.561168</td>\n",
       "      <td>-0.016808</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>0.501080</td>\n",
       "      <td>0.499186</td>\n",
       "      <td>-0.151567</td>\n",
       "      <td>0.999611</td>\n",
       "      <td>0.511735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174769</td>\n",
       "      <td>0.505163</td>\n",
       "      <td>0.917107</td>\n",
       "      <td>0.679398</td>\n",
       "      <td>-0.072136</td>\n",
       "      <td>0.854314</td>\n",
       "      <td>0.897946</td>\n",
       "      <td>0.663390</td>\n",
       "      <td>0.123349</td>\n",
       "      <td>0.418985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H</td>\n",
       "      <td>0.470527</td>\n",
       "      <td>0.561652</td>\n",
       "      <td>-0.022970</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>0.501089</td>\n",
       "      <td>0.499896</td>\n",
       "      <td>-0.151015</td>\n",
       "      <td>0.999606</td>\n",
       "      <td>0.511577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175588</td>\n",
       "      <td>0.507696</td>\n",
       "      <td>0.917283</td>\n",
       "      <td>0.679368</td>\n",
       "      <td>-0.059479</td>\n",
       "      <td>0.858189</td>\n",
       "      <td>0.897454</td>\n",
       "      <td>0.649829</td>\n",
       "      <td>0.127135</td>\n",
       "      <td>0.422249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H</td>\n",
       "      <td>0.470458</td>\n",
       "      <td>0.561586</td>\n",
       "      <td>-0.023488</td>\n",
       "      <td>0.999471</td>\n",
       "      <td>0.501087</td>\n",
       "      <td>0.501635</td>\n",
       "      <td>-0.149589</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170679</td>\n",
       "      <td>0.510499</td>\n",
       "      <td>0.918008</td>\n",
       "      <td>0.679460</td>\n",
       "      <td>-0.060940</td>\n",
       "      <td>0.861988</td>\n",
       "      <td>0.897331</td>\n",
       "      <td>0.653301</td>\n",
       "      <td>0.122035</td>\n",
       "      <td>0.425281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H</td>\n",
       "      <td>0.470431</td>\n",
       "      <td>0.560886</td>\n",
       "      <td>-0.022433</td>\n",
       "      <td>0.999432</td>\n",
       "      <td>0.501091</td>\n",
       "      <td>0.502017</td>\n",
       "      <td>-0.146421</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.511343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158384</td>\n",
       "      <td>0.509018</td>\n",
       "      <td>0.918341</td>\n",
       "      <td>0.679501</td>\n",
       "      <td>-0.072537</td>\n",
       "      <td>0.864205</td>\n",
       "      <td>0.897770</td>\n",
       "      <td>0.654864</td>\n",
       "      <td>0.108244</td>\n",
       "      <td>0.425387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label    nose_x    nose_y    nose_z    nose_v  left_shoulder_x  \\\n",
       "0     H  0.468005  0.560652 -0.020740  0.999619         0.501118   \n",
       "1     H  0.470203  0.561168 -0.016808  0.999572         0.501080   \n",
       "2     H  0.470527  0.561652 -0.022970  0.999516         0.501089   \n",
       "3     H  0.470458  0.561586 -0.023488  0.999471         0.501087   \n",
       "4     H  0.470431  0.560886 -0.022433  0.999432         0.501091   \n",
       "\n",
       "   left_shoulder_y  left_shoulder_z  left_shoulder_v  right_shoulder_x  ...  \\\n",
       "0         0.497534        -0.148594         0.999583          0.512936  ...   \n",
       "1         0.499186        -0.151567         0.999611          0.511735  ...   \n",
       "2         0.499896        -0.151015         0.999606          0.511577  ...   \n",
       "3         0.501635        -0.149589         0.999596          0.511364  ...   \n",
       "4         0.502017        -0.146421         0.999584          0.511343  ...   \n",
       "\n",
       "   right_heel_z  right_heel_v  left_foot_index_x  left_foot_index_y  \\\n",
       "0      0.168519      0.497204           0.916713           0.682381   \n",
       "1      0.174769      0.505163           0.917107           0.679398   \n",
       "2      0.175588      0.507696           0.917283           0.679368   \n",
       "3      0.170679      0.510499           0.918008           0.679460   \n",
       "4      0.158384      0.509018           0.918341           0.679501   \n",
       "\n",
       "   left_foot_index_z  left_foot_index_v  right_foot_index_x  \\\n",
       "0          -0.064803           0.822842            0.904292   \n",
       "1          -0.072136           0.854314            0.897946   \n",
       "2          -0.059479           0.858189            0.897454   \n",
       "3          -0.060940           0.861988            0.897331   \n",
       "4          -0.072537           0.864205            0.897770   \n",
       "\n",
       "   right_foot_index_y  right_foot_index_z  right_foot_index_v  \n",
       "0            0.667422            0.114563            0.406391  \n",
       "1            0.663390            0.123349            0.418985  \n",
       "2            0.649829            0.127135            0.422249  \n",
       "3            0.653301            0.122035            0.425281  \n",
       "4            0.654864            0.108244            0.425387  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = describe_dataset(\"./dataset.csv\")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and class\n",
    "\n",
    "X = df.drop(\"label\", axis=1) # features\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5812    L\n",
       "8003    C\n",
       "7132    C\n",
       "5785    L\n",
       "4796    L\n",
       "2856    L\n",
       "7125    C\n",
       "6746    C\n",
       "5880    L\n",
       "3424    L\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Train model using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms =[(\"LR\", LogisticRegression()),\n",
    "         (\"SVC\", SVC()),\n",
    "         ('KNN',KNeighborsClassifier()),\n",
    "         (\"DTC\", DecisionTreeClassifier()),\n",
    "         (\"SGDC\", SGDClassifier()),\n",
    "         (\"Ridge\", RidgeClassifier()),\n",
    "         ('RF', RandomForestClassifier()),]\n",
    "\n",
    "models = {}\n",
    "final_results = []\n",
    "\n",
    "for name, model in algorithms:\n",
    "    trained_model = model.fit(X_train, y_train)\n",
    "    models[name] = trained_model\n",
    "\n",
    "    # Evaluate model\n",
    "    model_results = model.predict(X_test)\n",
    "\n",
    "    p_score = precision_score(y_test, model_results, average=\"macro\")\n",
    "    a_score = accuracy_score(y_test, model_results)\n",
    "    f1_score_result = f1_score(y_test, model_results, average=None, labels=[\"C\", \"L\", \"H\"])\n",
    "    final_results.append(( name, p_score, a_score, f1_score_result ))\n",
    "\n",
    "\n",
    "final_results.sort(key=lambda k: k[3][0] + k[3][1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Accuracy score</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.998975</td>\n",
       "      <td>[0.9986684420772303, 0.9985082048731975, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.998680</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>[0.998220640569395, 0.998015873015873, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC</td>\n",
       "      <td>0.997823</td>\n",
       "      <td>0.997608</td>\n",
       "      <td>[0.9968930315135375, 0.9970178926441352, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.996071</td>\n",
       "      <td>0.995899</td>\n",
       "      <td>[0.9946428571428572, 0.9940711462450592, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.989276</td>\n",
       "      <td>0.989747</td>\n",
       "      <td>[0.9865107913669063, 0.9906357811729917, 0.993...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGDC</td>\n",
       "      <td>0.989549</td>\n",
       "      <td>0.989747</td>\n",
       "      <td>[0.9865107913669063, 0.9891732283464566, 0.994...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.986202</td>\n",
       "      <td>0.986329</td>\n",
       "      <td>[0.9819168173598554, 0.9853085210577864, 0.993...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Precision Score  Accuracy score  \\\n",
       "0     RF         0.999077        0.998975   \n",
       "1    KNN         0.998680        0.998633   \n",
       "2    DTC         0.997823        0.997608   \n",
       "3    SVC         0.996071        0.995899   \n",
       "4     LR         0.989276        0.989747   \n",
       "5   SGDC         0.989549        0.989747   \n",
       "6  Ridge         0.986202        0.986329   \n",
       "\n",
       "                                            F1 score  \n",
       "0      [0.9986684420772303, 0.9985082048731975, 1.0]  \n",
       "1        [0.998220640569395, 0.998015873015873, 1.0]  \n",
       "2  [0.9968930315135375, 0.9970178926441352, 0.999...  \n",
       "3      [0.9946428571428572, 0.9940711462450592, 1.0]  \n",
       "4  [0.9865107913669063, 0.9906357811729917, 0.993...  \n",
       "5  [0.9865107913669063, 0.9891732283464566, 0.994...  \n",
       "6  [0.9819168173598554, 0.9853085210577864, 0.993...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_results, columns=[\"Model\", \"Precision Score\", \"Accuracy score\" , \"F1 score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Dumped model using pickle\n",
    "\n",
    "According to the evaluations, there are multiple good models at the moment, therefore, I will pick the Random Forrest model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the best model to a pickle file\n",
    "import pickle\n",
    "\n",
    "with open(\"./plank_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(models[\"RF\"], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train model using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"label\", axis=1) # features\n",
    "y = df[\"label\"]\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = LabelBinarizer().fit_transform(y)\n",
    "\n",
    "y = y.astype(int)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y = y.reshape(len(y), 1)\n",
    "y = onehot_encoder.fit_transform(y)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(68, input_dim=68, activation='relu'))\n",
    "model.add(Dense(34, activation='relu'))\n",
    "model.add(Dense(17, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize=(7, 5), fontsize=14):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix.\n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names,\n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# define confusion matrix\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print_confusion_matrix(cm, ['correct', 'low back', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Dump the best model to a pickle file\n",
    "with open(\"./plank_model_deep_learning.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9260f401923fb5c4108c543a7d176de9733d378b3752e49535ad7c43c2271b65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
